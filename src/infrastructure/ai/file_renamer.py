"""
AI æ–‡ä»¶é‡å‘½åå™¨æ¨¡å—ã€‚

å®ç° IFileRenamer æ¥å£ï¼Œä½¿ç”¨ AI ç”Ÿæˆæ–‡ä»¶é‡å‘½åæ˜ å°„ã€‚
"""

import json
import logging
from typing import Any, Dict, List, Optional

from src.core.exceptions import (
    AICircuitBreakerError,
    AIKeyExhaustedError,
)
from src.core.interfaces.adapters import IFileRenamer, RenameResult
from src.services.ai_debug_service import ai_debug_service

from .api_client import OpenAIClient
from .circuit_breaker import CircuitBreaker
from .key_pool import KeyPool
from .prompts import (
    MULTI_FILE_RENAME_STANDARD_PROMPT,
    MULTI_FILE_RENAME_WITH_TVDB_PROMPT,
)
from .schemas import MULTI_FILE_RENAME_RESPONSE_FORMAT

logger = logging.getLogger(__name__)


# é»˜è®¤æ‰¹æ¬¡å¤§å°
DEFAULT_BATCH_SIZE = 30


class AIFileRenamer(IFileRenamer):
    """
    AI æ–‡ä»¶é‡å‘½åå™¨ã€‚

    å®ç° IFileRenamer æ¥å£ï¼Œä½¿ç”¨ OpenAI API ç”Ÿæˆæ–‡ä»¶é‡å‘½åæ˜ å°„ã€‚
    æ”¯æŒ TVDB æ•°æ®ã€æ–‡ä»¶å¤¹ç»“æ„è¾“å…¥å’Œæ‰¹é‡å¤„ç†ã€‚

    Example:
        >>> renamer = AIFileRenamer(key_pool, circuit_breaker)
        >>> result = renamer.generate_rename_mapping(
        ...     files=['[ANi] Title - 01 [1080P].mp4'],
        ...     category='tv',
        ...     anime_title='åŠ¨æ¼«æ ‡é¢˜'
        ... )
        >>> if result:
        ...     print(result.main_files)
    """

    def __init__(
        self,
        key_pool: KeyPool,
        circuit_breaker: CircuitBreaker,
        api_client: Optional[OpenAIClient] = None,
        max_retries: int = 3,
        batch_size: int = DEFAULT_BATCH_SIZE
    ):
        """
        åˆå§‹åŒ–æ–‡ä»¶é‡å‘½åå™¨ã€‚

        Args:
            key_pool: API Key æ± 
            circuit_breaker: ç†”æ–­å™¨
            api_client: API å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œé»˜è®¤åˆ›å»ºæ–°å®ä¾‹ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            batch_size: æ‰¹é‡å¤„ç†æ–‡ä»¶æ•°
        """
        self._key_pool = key_pool
        self._circuit_breaker = circuit_breaker
        self._api_client = api_client or OpenAIClient(timeout=60)
        self._max_retries = max_retries
        self._batch_size = batch_size

    def generate_rename_mapping(
        self,
        files: List[str],
        category: str,
        anime_title: Optional[str] = None,
        folder_structure: Optional[str] = None,
        tvdb_data: Optional[Dict[str, Any]] = None
    ) -> Optional[RenameResult]:
        """
        ç”Ÿæˆæ–‡ä»¶é‡å‘½åæ˜ å°„ã€‚

        æ”¯æŒæ‰¹é‡å¤„ç†å¤§æ–‡ä»¶åˆ—è¡¨ï¼Œè‡ªåŠ¨åˆ†æ‰¹è°ƒç”¨ AIã€‚

        Args:
            files: æ–‡ä»¶ååˆ—è¡¨
            category: å†…å®¹ç±»å‹ ('tv' æˆ– 'movie')
            anime_title: åŠ¨æ¼«æ ‡é¢˜ï¼ˆç”¨äºé‡å‘½åï¼‰
            folder_structure: æ–‡ä»¶å¤¹ç»“æ„ä¿¡æ¯
            tvdb_data: TVDB å…ƒæ•°æ®

        Returns:
            RenameResult: é‡å‘½åç»“æœ
            None: å¤„ç†å¤±è´¥

        Raises:
            AICircuitBreakerError: ç†”æ–­å™¨å·²å¼€å¯
            AIKeyExhaustedError: æ²¡æœ‰å¯ç”¨çš„ API Key
        """
        if not files:
            logger.warning('ğŸ“­ æ²¡æœ‰æ–‡ä»¶éœ€è¦å¤„ç†')
            return RenameResult()

        # æ£€æŸ¥ç†”æ–­å™¨æ˜¯å¦å…è®¸è¯·æ±‚
        if not self._circuit_breaker.allow_request():
            remaining = self._circuit_breaker.get_remaining_seconds()
            state = self._circuit_breaker.state.value
            logger.warning(
                f'ğŸ”´ [{self._key_pool.purpose}] ç†”æ–­å™¨çŠ¶æ€: {state}ï¼Œ'
                f'å‰©ä½™ {remaining:.0f}s'
            )
            raise AICircuitBreakerError(
                message=f'ç†”æ–­å™¨çŠ¶æ€: {state}',
                remaining_seconds=remaining
            )

        logger.info(f'ğŸ¤– å¼€å§‹å¤„ç† {len(files)} ä¸ªæ–‡ä»¶çš„é‡å‘½å')

        # å¦‚æœæ–‡ä»¶æ•°é‡è¶…è¿‡æ‰¹æ¬¡å¤§å°ï¼Œåˆ†æ‰¹å¤„ç†
        if len(files) > self._batch_size:
            return self._process_batches(
                files=files,
                category=category,
                anime_title=anime_title,
                folder_structure=folder_structure,
                tvdb_data=tvdb_data
            )
        else:
            return self._process_single_batch(
                files=files,
                category=category,
                anime_title=anime_title,
                folder_structure=folder_structure,
                tvdb_data=tvdb_data,
                previous_hardlinks=[]
            )

    def _process_batches(
        self,
        files: List[str],
        category: str,
        anime_title: Optional[str],
        folder_structure: Optional[str],
        tvdb_data: Optional[Dict[str, Any]]
    ) -> Optional[RenameResult]:
        """
        åˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶åˆ—è¡¨ã€‚

        Args:
            files: æ–‡ä»¶ååˆ—è¡¨
            category: å†…å®¹ç±»å‹
            anime_title: åŠ¨æ¼«æ ‡é¢˜
            folder_structure: æ–‡ä»¶å¤¹ç»“æ„
            tvdb_data: TVDB æ•°æ®

        Returns:
            åˆå¹¶åçš„ RenameResult æˆ– None
        """
        merged_result = RenameResult()
        previous_hardlinks: List[str] = []

        total_batches = (len(files) + self._batch_size - 1) // self._batch_size

        for batch_idx in range(total_batches):
            start = batch_idx * self._batch_size
            end = min(start + self._batch_size, len(files))
            batch_files = files[start:end]

            logger.info(
                f'ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}: '
                f'{len(batch_files)} ä¸ªæ–‡ä»¶'
            )

            batch_result = self._process_single_batch(
                files=batch_files,
                category=category,
                anime_title=anime_title,
                folder_structure=folder_structure,
                tvdb_data=tvdb_data,
                previous_hardlinks=previous_hardlinks
            )

            if batch_result is None:
                logger.error(f'âŒ æ‰¹æ¬¡ {batch_idx + 1} å¤„ç†å¤±è´¥')
                continue

            # åˆå¹¶ç»“æœ
            merged_result.main_files.update(batch_result.main_files)
            merged_result.skipped_files.extend(batch_result.skipped_files)

            # åˆå¹¶å­£åº¦ä¿¡æ¯
            for season_key, season_info in batch_result.seasons_info.items():
                if season_key in merged_result.seasons_info:
                    # ç´¯åŠ é›†æ•°
                    existing = merged_result.seasons_info[season_key]
                    if isinstance(existing, dict) and isinstance(season_info, dict):
                        existing['count'] = (
                            existing.get('count', 0) + season_info.get('count', 0)
                        )
                else:
                    merged_result.seasons_info[season_key] = season_info

            # æ›´æ–°å·²å¤„ç†çš„ç¡¬é“¾æ¥åˆ—è¡¨ï¼Œç”¨äºåç»­æ‰¹æ¬¡å†²çªæ£€æµ‹
            previous_hardlinks.extend(batch_result.main_files.values())

            # ä¿ç•™æœ€åä¸€æ‰¹çš„ patterns
            merged_result.patterns = batch_result.patterns

        if not merged_result.has_files:
            logger.warning('ğŸ“­ æ‰¹é‡å¤„ç†å®Œæˆä½†æ²¡æœ‰ç”Ÿæˆä»»ä½•é‡å‘½åæ˜ å°„')
            return None

        logger.info(
            f'âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {merged_result.file_count} ä¸ªæ–‡ä»¶æ˜ å°„, '
            f'{merged_result.skipped_count} ä¸ªè·³è¿‡'
        )
        return merged_result

    def _process_single_batch(
        self,
        files: List[str],
        category: str,
        anime_title: Optional[str],
        folder_structure: Optional[str],
        tvdb_data: Optional[Dict[str, Any]],
        previous_hardlinks: List[str]
    ) -> Optional[RenameResult]:
        """
        å¤„ç†å•ä¸ªæ‰¹æ¬¡çš„æ–‡ä»¶ã€‚

        Args:
            files: æ–‡ä»¶ååˆ—è¡¨
            category: å†…å®¹ç±»å‹
            anime_title: åŠ¨æ¼«æ ‡é¢˜
            folder_structure: æ–‡ä»¶å¤¹ç»“æ„
            tvdb_data: TVDB æ•°æ®
            previous_hardlinks: å·²åˆ›å»ºçš„ç¡¬é“¾æ¥åˆ—è¡¨ï¼ˆç”¨äºå†²çªæ£€æµ‹ï¼‰

        Returns:
            RenameResult æˆ– None
        """
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = self._build_user_message(
            files=files,
            category=category,
            anime_title=anime_title,
            folder_structure=folder_structure,
            tvdb_data=tvdb_data,
            previous_hardlinks=previous_hardlinks
        )

        # é€‰æ‹©æç¤ºè¯
        system_prompt = (
            MULTI_FILE_RENAME_WITH_TVDB_PROMPT
            if tvdb_data
            else MULTI_FILE_RENAME_STANDARD_PROMPT
        )

        for attempt in range(self._max_retries):
            # é¢„ç•™ Key
            reservation = self._key_pool.reserve()
            if not reservation:
                logger.error(f'âŒ [{self._key_pool.purpose}] æ²¡æœ‰å¯ç”¨çš„ API Key')
                raise AIKeyExhaustedError(
                    message='æ²¡æœ‰å¯ç”¨çš„ API Key'
                )

            logger.debug(
                f'ğŸ”‘ å°è¯• {attempt + 1}/{self._max_retries}: '
                f'ä½¿ç”¨ Key {reservation.key_id}'
            )

            # è°ƒç”¨ API
            response = self._api_client.call(
                base_url=reservation.base_url,
                api_key=reservation.api_key,
                model=reservation.model,
                messages=[
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_message}
                ],
                response_format=MULTI_FILE_RENAME_RESPONSE_FORMAT
            )

            if response.success:
                # æŠ¥å‘ŠæˆåŠŸç»™ Key Pool
                self._key_pool.report_success(
                    reservation.key_id,
                    response_time_ms=response.response_time_ms
                )

                # æŠ¥å‘ŠæˆåŠŸç»™ç†”æ–­å™¨ï¼ˆç”¨äºåŠå¼€çŠ¶æ€æ¢æµ‹ï¼‰
                self._circuit_breaker.report_success()

                # è®°å½• AI è°ƒè¯•æ—¥å¿—
                if ai_debug_service.enabled:
                    ai_debug_service.log_ai_interaction(
                        operation='multi_file_rename',
                        input_data={
                            'files': files,
                            'category': category,
                            'anime_title': anime_title,
                            'folder_structure': folder_structure,
                            'tvdb_data': tvdb_data,
                            'previous_hardlinks': previous_hardlinks
                        },
                        output_data=response.content,
                        model=reservation.model,
                        response_time_ms=response.response_time_ms,
                        key_id=reservation.key_id,
                        success=True
                    )

                # è§£æå“åº”
                result = self._parse_response(response.content)
                if result:
                    logger.info(
                        f'âœ… æ–‡ä»¶é‡å‘½åæˆåŠŸ: {result.file_count} ä¸ªæ–‡ä»¶ '
                        f'({response.response_time_ms}ms)'
                    )
                    return result
                else:
                    logger.warning('âš ï¸ å“åº”è§£æå¤±è´¥ï¼Œå°è¯•é‡è¯•')
                    continue
            else:
                # è®°å½• AI è°ƒè¯•æ—¥å¿—ï¼ˆå¤±è´¥ï¼‰
                if ai_debug_service.enabled:
                    ai_debug_service.log_ai_interaction(
                        operation='multi_file_rename',
                        input_data={
                            'files': files,
                            'category': category,
                            'anime_title': anime_title
                        },
                        output_data=None,
                        model=reservation.model,
                        response_time_ms=response.response_time_ms,
                        key_id=reservation.key_id,
                        success=False,
                        error_message=response.error_message
                    )

                # æŠ¥å‘Šé”™è¯¯ç»™ Key Poolï¼ˆä½¿ç”¨çŠ¶æ€ç åŒºåˆ†é”™è¯¯ç±»å‹ï¼‰
                retry_after = None
                if response.error_code == 429:
                    retry_after = self._extract_retry_after(response.error_message)

                self._key_pool.report_error(
                    reservation.key_id,
                    response.error_message or 'Unknown error',
                    status_code=response.error_code,
                    retry_after=retry_after
                )

                # æŠ¥å‘Šå¤±è´¥ç»™ç†”æ–­å™¨ï¼ˆç”¨äºåŠå¼€çŠ¶æ€æ¢æµ‹ï¼‰
                self._circuit_breaker.report_failure(response.error_message)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘ç†”æ–­
                pool_status = self._key_pool.get_status()
                if pool_status['all_in_long_cooling']:
                    self._circuit_breaker.trip(
                        reason='æ‰€æœ‰ Key éƒ½ä¸å¯ç”¨ï¼ˆé•¿å†·å´æˆ–å·²ç¦ç”¨ï¼‰'
                    )
                    raise AICircuitBreakerError(
                        message='æ‰€æœ‰ Key éƒ½ä¸å¯ç”¨ï¼Œè§¦å‘ç†”æ–­',
                        remaining_seconds=self._circuit_breaker.get_remaining_seconds()
                    )

        logger.error(
            f'âŒ æ–‡ä»¶é‡å‘½åå¤±è´¥: é‡è¯• {self._max_retries} æ¬¡åä»å¤±è´¥'
        )
        return None

    def _build_user_message(
        self,
        files: List[str],
        category: str,
        anime_title: Optional[str],
        folder_structure: Optional[str],
        tvdb_data: Optional[Dict[str, Any]],
        previous_hardlinks: List[str]
    ) -> str:
        """
        æ„å»ºå‘é€ç»™ AI çš„ç”¨æˆ·æ¶ˆæ¯ã€‚

        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            category: å†…å®¹ç±»å‹
            anime_title: åŠ¨æ¼«æ ‡é¢˜
            folder_structure: æ–‡ä»¶å¤¹ç»“æ„
            tvdb_data: TVDB æ•°æ®
            previous_hardlinks: å·²åˆ›å»ºçš„ç¡¬é“¾æ¥

        Returns:
            æ ¼å¼åŒ–çš„ç”¨æˆ·æ¶ˆæ¯
        """
        message_parts = []

        # åŸºæœ¬ä¿¡æ¯
        message_parts.append(f'**Category**: {category}')

        if anime_title:
            message_parts.append(f'**Anime Title**: {anime_title}')

        # æ–‡ä»¶åˆ—è¡¨
        files_json = json.dumps({'files': files}, ensure_ascii=False, indent=2)
        message_parts.append(f'**Files**:\n```json\n{files_json}\n```')

        # æ–‡ä»¶å¤¹ç»“æ„
        if folder_structure:
            message_parts.append(f'**Folder Structure**:\n```\n{folder_structure}\n```')

        # TVDB æ•°æ®
        if tvdb_data:
            tvdb_json = json.dumps(tvdb_data, ensure_ascii=False, indent=2)
            message_parts.append(f'**TVDB Data**:\n```json\n{tvdb_json}\n```')

        # å·²åˆ›å»ºçš„ç¡¬é“¾æ¥ï¼ˆç”¨äºæ‰¹é‡å¤„ç†æ—¶é¿å…å†²çªï¼‰
        if previous_hardlinks:
            hardlinks_json = json.dumps(
                {'previous_hardlinks': previous_hardlinks},
                ensure_ascii=False,
                indent=2
            )
            message_parts.append(
                f'**Previous Hardlinks**:\n```json\n{hardlinks_json}\n```'
            )

        return '\n\n'.join(message_parts)

    def _parse_response(self, content: Optional[str]) -> Optional[RenameResult]:
        """
        è§£æ AI å“åº”å†…å®¹ã€‚

        Args:
            content: AI å“åº”å†…å®¹

        Returns:
            RenameResult æˆ– None
        """
        if not content:
            return None

        try:
            # æ¸…ç† markdown ä»£ç å—
            cleaned = content.strip()
            if cleaned.startswith('```json'):
                cleaned = cleaned[7:]
            if cleaned.startswith('```'):
                cleaned = cleaned[3:]
            if cleaned.endswith('```'):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()

            data = json.loads(cleaned)

            # æ„å»º RenameResult
            main_files = data.get('main_files', {})
            skipped_files = data.get('skipped_files', [])
            seasons_info = data.get('seasons_info', {})

            # æ„å»º patterns ä¿¡æ¯
            patterns = {
                'subtitle_group_regex': data.get('subtitle_group_regex', ''),
                'full_title_regex': data.get('full_title_regex', ''),
                'clean_title_regex': data.get('clean_title_regex', ''),
                'episode_regex': data.get('episode_regex', ''),
                'special_tag_regex': data.get('special_tag_regex', ''),
                'quality_regex': data.get('quality_regex', ''),
                'platform_regex': data.get('platform_regex', ''),
                'source_regex': data.get('source_regex', ''),
                'codec_regex': data.get('codec_regex', ''),
                'subtitle_type_regex': data.get('subtitle_type_regex', ''),
                'format_regex': data.get('format_regex', ''),
                'anime_full_title': data.get('anime_full_title', ''),
                'anime_clean_title': data.get('anime_clean_title', ''),
                'subtitle_group_name': data.get('subtitle_group_name', ''),
                'season': data.get('season', 1),
                'category': data.get('category', 'tv'),
                'method': 'ai'
            }

            return RenameResult(
                main_files=main_files,
                skipped_files=skipped_files,
                seasons_info=seasons_info,
                patterns=patterns,
                method='ai'
            )

        except json.JSONDecodeError as e:
            logger.error(f'âŒ JSON è§£æå¤±è´¥: {e}')
            logger.debug(f'å“åº”å†…å®¹: {content[:500]}')
            return None

        except (KeyError, TypeError, ValueError) as e:
            logger.error(f'âŒ æ•°æ®æå–å¤±è´¥: {e}')
            return None

        except Exception as e:
            logger.exception(f'âŒ å“åº”è§£ææœªé¢„æœŸé”™è¯¯: {e}')
            return None

    def _extract_retry_after(self, error_message: Optional[str]) -> Optional[float]:
        """
        ä»é”™è¯¯æ¶ˆæ¯ä¸­æå– retry-after æ—¶é—´ã€‚

        Args:
            error_message: é”™è¯¯æ¶ˆæ¯

        Returns:
            é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰æˆ– None
        """
        if not error_message:
            return None

        import re

        # å°è¯•åŒ¹é…å¸¸è§çš„ retry-after æ ¼å¼
        patterns = [
            r'retry.?after[:\s]+(\d+(?:\.\d+)?)\s*(?:s|seconds?)?',
            r'wait[:\s]+(\d+(?:\.\d+)?)\s*(?:s|seconds?)?',
            r'(\d+(?:\.\d+)?)\s*(?:s|seconds?)\s*(?:before|until)',
        ]

        for pattern in patterns:
            match = re.search(pattern, error_message, re.IGNORECASE)
            if match:
                try:
                    return float(match.group(1))
                except ValueError:
                    continue

        return None
